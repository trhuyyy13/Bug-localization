{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":11280721,"sourceType":"datasetVersion","datasetId":7052679},{"sourceId":11265211,"sourceType":"datasetVersion","datasetId":7041476}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Load d·ªØ li·ªáu ƒë√£ x·ª≠ l√≠","metadata":{"id":"-eUizc5QmpX4"}},{"cell_type":"code","source":"!pip install nltk\n","metadata":{"id":"9qfVWdges0io","outputId":"e6051f73-0867-4eb4-b5c0-984722d836d3","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:05.951696Z","iopub.execute_input":"2025-04-14T15:42:05.951893Z","iopub.status.idle":"2025-04-14T15:42:10.729994Z","shell.execute_reply.started":"2025-04-14T15:42:05.951876Z","shell.execute_reply":"2025-04-14T15:42:10.729003Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import nltk\nnltk.download('averaged_perceptron_tagger_eng')","metadata":{"id":"8SUNdusXgQ-3","outputId":"937573b4-53fb-4bb5-9c39-84eb53bc1890","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:10.732238Z","iopub.execute_input":"2025-04-14T15:42:10.732532Z","iopub.status.idle":"2025-04-14T15:42:13.183785Z","shell.execute_reply.started":"2025-04-14T15:42:10.732508Z","shell.execute_reply":"2025-04-14T15:42:13.183039Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# English stop words\nstop_words = set(\n    ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your',\n     'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her',\n     'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs',\n     'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n     'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n     'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n     'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about',\n     'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above',\n     'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n     'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n     'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some',\n     'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very',\n     's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o',\n     're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven',\n     'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won',\n     'wouldn', 'b', 'c', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'n', 'p', 'q', 'u', 'v',\n     'w', 'x', 'z', 'us'])\n\n# Java language keywords\njava_keywords = set(\n    ['abstract', 'assert', 'boolean', 'break', 'byte', 'case',\n     'catch', 'char', 'class', 'const', 'continue', 'default', 'do', 'double',\n     'else', 'enum', 'extends', 'false', 'final', 'finally', 'float', 'for', 'goto',\n     'if', 'implements', 'import', 'instanceof', 'int', 'interface', 'long',\n     'native', 'new', 'null', 'package', 'private', 'protected', 'public', 'return',\n     'short', 'static', 'strictfp', 'super', 'switch', 'synchronized', 'this',\n     'throw', 'throws', 'transient', 'true', 'try', 'void', 'volatile', 'while'])\n\nfrom collections import namedtuple\nfrom pathlib import Path\n\n# Dataset root directory (ƒëi·ªÅu ch·ªânh ƒë∆∞·ªùng d·∫´n n·∫øu c·∫ßn)\n_DATASET_ROOT = Path('/content/drive/MyDrive/Colab Notebooks/NLP/Task bug localization/')\n\nDataset = namedtuple('Dataset', ['name', 'src', 'bug_repo', 'repo_url', 'features'])\n\n# C√°c dataset ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a\naspectj = Dataset(\n    'aspectj',\n    _DATASET_ROOT / 'source files/org.aspectj',\n    _DATASET_ROOT / 'bug reports/AspectJ.txt',\n    \"https://github.com/eclipse/org.aspectj/tree/bug433351.git\",\n    _DATASET_ROOT / 'bug reports/AspectJ.xlsx'\n)\n\neclipse = Dataset(\n    'eclipse',\n    _DATASET_ROOT / 'source files/eclipse.platform.ui-johna-402445',\n    _DATASET_ROOT / 'bug reports/Eclipse_Platform_UI.txt',\n    \"https://github.com/eclipse/eclipse.platform.ui.git\",\n    _DATASET_ROOT / 'bug reports/Eclipse_Platform_UI.xlsx'\n)\n\nswt = Dataset(\n    'swt',\n    _DATASET_ROOT / 'source files/eclipse.platform.swt-xulrunner-31',\n    _DATASET_ROOT / 'bug reports/SWT.txt',\n    \"https://github.com/eclipse/eclipse.platform.swt.git\",\n    _DATASET_ROOT / 'bug reports/SWT.xlsx'\n)\n\ntomcat = Dataset(\n    'tomcat',\n    _DATASET_ROOT / 'source files/tomcat-7.0.51',\n    _DATASET_ROOT / 'bug reports/Tomcat.txt',\n    \"https://github.com/apache/tomcat.git\",\n    _DATASET_ROOT / 'bug reports/Tomcat.xlsx'\n)\n\nbirt = Dataset(\n    'birt',\n    _DATASET_ROOT / 'source files/birt-20140211-1400',\n    _DATASET_ROOT / 'bug reports/Birt.txt',\n    \"https://github.com/apache/birt.git\",\n    _DATASET_ROOT / 'bug reports/Birt.xlsx'\n)\n\n\n### Current dataset in use. (change this name to change the dataset)\nDATASET = tomcat\n\nclass BugReport:\n    \"\"\"Class representing each bug report\"\"\"\n    __slots__ = ['summary', 'description', 'fixed_files', 'report_time', 'pos_tagged_summary', 'pos_tagged_description','stack_traces','stack_traces_remove']\n\n    def __init__(self, summary, description, fixed_files, report_time):\n        self.summary = summary\n        self.description = description\n        self.fixed_files = fixed_files\n        self.report_time = report_time\n        self.pos_tagged_summary = None\n        self.pos_tagged_description = None\n        self.stack_traces = None\n        self.stack_traces_remove = None\n\nclass SourceFile:\n    \"\"\"Class representing each source file\"\"\"\n    __slots__ = ['all_content', 'comments', 'class_names', 'attributes', 'method_names', 'variables', 'file_name',\n                 'pos_tagged_comments', 'exact_file_name', 'package_name']\n\n    def __init__(self, all_content, comments, class_names, attributes, method_names, variables, file_name,\n                 package_name):\n        self.all_content = all_content\n        self.comments = comments\n        self.class_names = class_names\n        self.attributes = attributes\n        self.method_names = method_names\n        self.variables = variables\n        self.file_name = file_name\n        self.exact_file_name = file_name[0]\n        self.package_name = package_name\n        self.pos_tagged_comments = None\n\n\nclass Parser:\n    \"\"\"Class containing different parsers\"\"\"\n    __slots__ = ['name', 'src', 'bug_repo']\n\n    def __init__(self, pro):\n        self.name = pro.name\n        self.src = pro.src\n        self.bug_repo = pro.bug_repo\n\n    def report_parser(self):\n        reader = csv.DictReader(open(self.bug_repo, \"r\"), delimiter=\"\\t\")\n        bug_reports = OrderedDict()\n        # raw_texts = []\n        # fixed_files = []\n        for line in reader:\n            # line[\"raw_text\"] = line[\"summary\"] + ' ' + line[\"description\"]\n            line[\"report_time\"] = datetime.strptime(line[\"report_time\"], \"%Y-%m-%d %H:%M:%S\")\n            temp = line[\"files\"].strip().split(\".java\")\n            length = len(temp)\n            x = []\n            for i, f in enumerate(temp):\n                if i == (length - 1):\n                    x.append(os.path.normpath(f))\n                    continue\n                x.append(os.path.normpath(f + \".java\"))\n            line[\"files\"] = x\n            bug_reports[line[\"bug_id\"]] = BugReport(line[\"summary\"], line[\"description\"], line[\"files\"],\n                                                    line[\"report_time\"])\n        # bug_reports = tsv2dict(self.bug_repo)\n\n        return bug_reports\n\n    def src_parser(self):\n        \"\"\"Parse source code directory of a program and colect its java files\"\"\"\n\n        # Gettting the list of source files recursively from the source directory\n        src_addresses = glob.glob(str(self.src) + '/**/*.java', recursive=True)\n        print(src_addresses)\n        # Creating a java lexer instance for pygments.lex() method\n        java_lexer = JavaLexer()\n        src_files = OrderedDict()\n        # src_files = dict()\n        # Looping to parse each source file\n        for src_file in src_addresses:\n            with open(src_file, encoding='latin-1') as file:\n                src = file.read()\n\n            # Placeholder for different parts of a source file\n            comments = ''\n            class_names = []\n            attributes = []\n            method_names = []\n            variables = []\n\n            # Source parsing\n            parse_tree = None\n            try:\n                parse_tree = javalang.parse.parse(src)\n                for path, node in parse_tree.filter(javalang.tree.VariableDeclarator):\n                    if isinstance(path[-2], javalang.tree.FieldDeclaration):\n                        attributes.append(node.name)\n                    elif isinstance(path[-2], javalang.tree.VariableDeclaration):\n                        variables.append(node.name)\n            except:\n                pass\n\n            # Triming the source file\n            ind = False\n            if parse_tree:\n                if parse_tree.imports:\n                    last_imp_path = parse_tree.imports[-1].path\n                    src = src[src.index(last_imp_path) + len(last_imp_path) + 1:]\n                elif parse_tree.package:\n                    package_name = parse_tree.package.name\n                    src = src[src.index(package_name) + len(package_name) + 1:]\n                else:  # no import and no package declaration\n                    ind = True\n            # javalang can't parse the source file\n            else:\n                ind = True\n\n            # Lexically tokenize the source file\n            lexed_src = pygments.lex(src, java_lexer)\n\n            for i, token in enumerate(lexed_src):\n                if token[0] in Token.Comment:\n                    if ind and i == 0 and token[0] is Token.Comment.Multiline:\n                        src = src[src.index(token[1]) + len(token[1]):]\n                        continue\n                    comments = comments + token[1]\n                elif token[0] is Token.Name.Class:\n                    class_names.append(token[1])\n                elif token[0] is Token.Name.Function:\n                    method_names.append(token[1])\n\n            # get the package declaration if exists\n            if parse_tree and parse_tree.package:\n                package_name = parse_tree.package.name\n            else:\n                package_name = None\n\n            if self.name == 'aspectj' or 'tomcat' or 'eclipse' or 'swt':\n                src_files[os.path.relpath(src_file, start=self.src)] = SourceFile(src, comments, class_names,\n                                                                                  attributes, method_names, variables, [\n                                                                                      os.path.basename(src_file).split(\n                                                                                          '.')[0]], package_name)\n            else:\n                # If source files has package declaration\n                if package_name:\n                    src_id = (package_name + '.' + os.path.basename(src_file))\n                else:\n                    src_id = os.path.basename(src_file)\n                src_files[src_id] = SourceFile(src, comments, class_names, attributes, method_names, variables,\n                                               [os.path.basename(src_file).split('.')[0]], package_name)\n            # print(src_files)\n            # print(\"===========\")\n        return src_files\n\n\nclass ReportPreprocessing:\n    \"\"\"Class preprocess bug reports\"\"\"\n    __slots__ = ['bug_reports']\n\n    def __init__(self, bug_reports):\n        self.bug_reports = bug_reports\n\n    def extract_stack_traces(self):\n        \"\"\"Extract stack traces from bug reports\"\"\"\n        pattern = re.compile(r' at (.*?)\\((.*?)\\)')\n        signs = ['.java', 'Unknown Source', 'Native Method']\n        for report in self.bug_reports.values():\n            st_canid = re.findall(pattern, report.description)\n            st = [x for x in st_canid if any(s in x[1] for s in signs)]\n            report.stack_traces = st\n\n    def extract_stack_traces_remove(self):\n        pattern = re.compile(r' at (.*?)\\((.*?)\\)')\n        signs = ['.java', 'Unknown Source', 'Native Method']\n        for report in self.bug_reports.values():\n            st_canid = re.findall(pattern, report.description)\n            st = [x for x in st_canid if any(s in x[1] for s in signs)]\n            at = []\n            for x in st:\n                if (x[1] == 'Unknown Source'):\n                    temp = 'Unknown'\n                    y = x[0]+ '(' + temp\n                else:\n                    y = x[0] + '(' + x[1] + ')'\n                at.append(y)\n            report.stack_traces_remove = at\n\n    def pos_tagging(self):\n        \"\"\"Extracing specific pos tags from bug reports raw_text\"\"\"\n        for report in self.bug_reports.values():\n            # Tokenizing using word_tokeize for more accurate pos-tagging\n            sum_tok = nltk.word_tokenize(report.summary)\n            desc_tok = nltk.word_tokenize(report.description)\n            sum_pos = nltk.pos_tag(sum_tok)\n            desc_pos = nltk.pos_tag(desc_tok)\n            report.pos_tagged_summary = [token for token, pos in sum_pos if 'NN' in pos or 'VB' in pos]\n            report.pos_tagged_description = [token for token, pos in desc_pos if 'NN' in pos or 'VB' in pos]\n\n    def tokenize(self):\n        \"\"\"Tokenize bug report intro tokens\"\"\"\n        for report in self.bug_reports.values():\n            report.summary = nltk.wordpunct_tokenize(report.summary)\n            report.description = nltk.wordpunct_tokenize(report.description)\n\n    def _split_camelcase(self, tokens):\n        # copy tokens\n        returning_tokens = tokens[:]\n        for token in tokens:\n            split_tokens = re.split(fr'[{string.punctuation}]+', token)\n            # if token is split into some other tokens\n            if len(split_tokens) > 1:\n                returning_tokens.remove(token)\n                # camel case detection for new tokens\n                for st in split_tokens:\n                    camel_split = inflection.underscore(st).split('_')\n                    if len(camel_split) > 1:\n                        returning_tokens.append(st)\n                        returning_tokens = returning_tokens + camel_split\n                    else:\n                        returning_tokens.append(st)\n            else:\n                camel_split = inflection.underscore(token).split('_')\n                if len(camel_split) > 1:\n                    returning_tokens = returning_tokens + camel_split\n        return returning_tokens\n\n    def split_camelcase(self):\n        \"\"\"Split camelcase indentifiers\"\"\"\n        for report in self.bug_reports.values():\n            report.summary = self._split_camelcase(report.summary)\n            report.description = self._split_camelcase(report.description)\n            report.pos_tagged_summary = self._split_camelcase(report.pos_tagged_summary)\n            report.pos_tagged_description = self._split_camelcase(report.pos_tagged_description)\n\n    def normalize(self):\n        \"\"\"remove punctuation, numbers and lowecase conversion\"\"\"\n        # build a translate table for punctuation and number removal\n        punctnum_table = str.maketrans({c: None for c in string.punctuation + string.digits})\n\n        for report in self.bug_reports.values():\n            summary_punctnum_rem = [token.translate(punctnum_table) for token in report.summary]\n            desc_punctnum_rem = [token.translate(punctnum_table) for token in report.description]\n            pos_sum_punctnum_rem = [token.translate(punctnum_table) for token in report.pos_tagged_summary]\n            pos_desc_punctnum_rem = [token.translate(punctnum_table) for token in report.pos_tagged_description]\n            report.summary = [token.lower() for token in summary_punctnum_rem if token]\n            report.description = [token.lower() for token in desc_punctnum_rem if token]\n            report.pos_tagged_summary = [token.lower() for token in pos_sum_punctnum_rem if token]\n            report.pos_tagged_description = [token.lower() for token in pos_desc_punctnum_rem if token]\n\n    def remove_stopwords(self):\n        \"\"\"removing stop word from tokens\"\"\"\n        for report in self.bug_reports.values():\n            report.summary = [token for token in report.summary if token not in stop_words]\n            report.description = [token for token in report.description if token not in stop_words]\n            report.pos_tagged_summary = [token for token in report.pos_tagged_summary if token not in stop_words]\n            report.pos_tagged_description = [token for token in report.pos_tagged_description if token not in stop_words]\n\n    def remove_java_keywords(self):\n        \"\"\"removing java language keywords from tokens\"\"\"\n        for report in self.bug_reports.values():\n            report.summary = [token for token in report.summary if token not in java_keywords]\n            report.description = [token for token in report.description if token not in java_keywords]\n            report.pos_tagged_summary = [token for token in report.pos_tagged_summary if token not in java_keywords]\n            report.pos_tagged_description = [token for token in report.pos_tagged_description if token not in java_keywords]\n\n    def stem(self):\n        # stemming tokens\n        stemmer = PorterStemmer()\n        for report in self.bug_reports.values():\n            report.summary = dict(\n                zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in report.summary], report.summary]))\n            report.description = dict(\n                zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in report.description], report.description]))\n            report.pos_tagged_summary = dict(\n                zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in report.pos_tagged_summary], report.pos_tagged_summary]))\n            report.pos_tagged_description = dict(\n                zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in report.pos_tagged_description], report.pos_tagged_description]))\n\n    def preprocess(self):\n        self.extract_stack_traces()\n        self.extract_stack_traces_remove()\n        self.pos_tagging()\n        self.tokenize()\n        self.split_camelcase()\n        self.normalize()\n        self.remove_stopwords()\n        self.remove_java_keywords()\n        self.stem()\n\nclass SrcPreprocessing:\n    \"\"\"class to preprocess source code\"\"\"\n    __slots__ = ['src_files']\n\n    def __init__(self, src_files):\n        self.src_files = src_files\n\n    def pos_tagging(self):\n        \"\"\"Extracing specific pos tags from comments\"\"\"\n        for src in self.src_files.values():\n            # tokenize using word_tokenize\n            comments_tok = nltk.word_tokenize(src.comments)\n            comments_pos = nltk.pos_tag(comments_tok)\n            src.pos_tagged_comments = [token for token, pos in comments_pos if 'NN' in pos or 'VB' in pos]\n\n    def tokenize(self):\n        \"\"\"tokenize source code to tokens\"\"\"\n        for src in self.src_files.values():\n            src.all_content = nltk.wordpunct_tokenize(src.all_content)\n            src.comments = nltk.wordpunct_tokenize(src.comments)\n\n    def _split_camelcase(self, tokens):\n        # copy token\n        returning_tokens = tokens[:]\n        for token in tokens:\n            split_tokens = re.split(fr'[{string.punctuation}]+', token)\n            # if token is split into some other tokens\n            if len(split_tokens) > 1:\n                returning_tokens.remove(token)\n                # camelcase defect for new tokens\n                for st in split_tokens:\n                    camel_split = inflection.underscore(st).split('_')\n                    if len(camel_split) > 1:\n                        returning_tokens.append(st)\n                        returning_tokens = returning_tokens + camel_split\n                    else:\n                        returning_tokens.append(st)\n            else:\n                camel_split = inflection.underscore(token).split('_')\n                if len(camel_split) > 1:\n                    returning_tokens = returning_tokens + camel_split\n        return returning_tokens\n\n    def split_camelcase(self):\n        # Split camelcase indenti\n        for src in self.src_files.values():\n            src.all_content = self._split_camelcase(src.all_content)\n            src.comments = self._split_camelcase(src.comments)\n            src.class_names = self._split_camelcase(src.class_names)\n            src.attributes = self._split_camelcase(src.attributes)\n            src.method_names = self._split_camelcase(src.method_names)\n            src.variables = self._split_camelcase(src.variables)\n            src.pos_tagged_comments = self._split_camelcase(src.pos_tagged_comments)\n\n    def normalize(self):\n        \"remove punctuation, number and lowercase conversion\"\n        # build a translate table for punctuation and number\n        punctnum_table = str.maketrans({c: None for c in string.punctuation + string.digits})\n        for src in self.src_files.values():\n            content_punctnum_rem = [token.translate(punctnum_table) for token in src.all_content]\n            comments_punctnum_rem = [token.translate(punctnum_table) for token in src.comments]\n            classnames_punctnum_rem = [token.translate(punctnum_table) for token in src.class_names]\n            attributes_punctnum_rem = [token.translate(punctnum_table) for token in src.attributes]\n            methodnames_punctnum_rem = [token.translate(punctnum_table) for token in src.method_names]\n            variables_punctnum_rem = [token.translate(punctnum_table) for token in src.variables]\n            filename_punctnum_rem = [token.translate(punctnum_table) for token in src.file_name]\n            pos_comments_punctnum_rem = [token.translate(punctnum_table) for token in src.pos_tagged_comments]\n\n            src.all_content = [token.lower() for token in content_punctnum_rem if token]\n            src.comments = [token.lower() for token in comments_punctnum_rem if token]\n            src.class_names = [token.lower() for token in classnames_punctnum_rem if token]\n            src.attributes = [token.lower() for token in attributes_punctnum_rem if token]\n            src.method_names = [token.lower() for token in methodnames_punctnum_rem if token]\n            src.variables = [token.lower() for token in variables_punctnum_rem if token]\n            src.file_name = [token.lower() for token in filename_punctnum_rem if token]\n            src.pos_tagged_comments = [token.lower() for token in pos_comments_punctnum_rem if token]\n\n    def remove_stopwords(self):\n        for src in self.src_files.values():\n            src.all_content = [token for token in src.all_content if token not in stop_words]\n            src.comments = [token for token in src.comments if token not in stop_words]\n            src.class_names = [token for token in src.class_names if token not in stop_words]\n            src.attributes = [token for token in src.attributes if token not in stop_words]\n            src.method_names = [token for token in src.method_names if token not in stop_words]\n            src.variables = [token for token in src.variables if token not in stop_words]\n            src.file_name = [token for token in src.file_name if token not in stop_words]\n            src.pos_tagged_comments = [token for token in src.pos_tagged_comments if token not in stop_words]\n\n    def remove_javakeywords(self):\n        for src in self.src_files.values():\n            src.all_content = [token for token in src.all_content if token not in java_keywords]\n            src.comments = [token for token in src.comments if token not in java_keywords]\n            src.class_names = [token for token in src.class_names if token not in java_keywords]\n            src.attributes = [token for token in src.attributes if token not in java_keywords]\n            src.method_names = [token for token in src.method_names if token not in java_keywords]\n            src.variables = [token for token in src.variables if token not in java_keywords]\n            src.file_name = [token for token in src.file_name if token not in java_keywords]\n            src.pos_tagged_comments = [token for token in src.pos_tagged_comments if token not in java_keywords]\n\n    def stem(self):\n        # stemming tokens\n        stemmer = PorterStemmer()\n        for src in self.src_files.values():\n            src.all_content = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.all_content], src.all_content]))\n            src.comments = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.comments], src.comments]))\n            src.class_names = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.class_names], src.class_names]))\n            src.attributes = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.attributes], src.attributes]))\n            src.method_names = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.method_names], src.method_names]))\n            src.variables = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.variables], src.variables]))\n            src.file_name = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.file_name], src.file_name]))\n            src.pos_tagged_comments = dict(zip(['stemmed', 'unstemmed'], [[stemmer.stem(token) for token in src.pos_tagged_comments], src.pos_tagged_comments]))\n\n\n    def preprocess(self):\n        self.pos_tagging()\n        self.tokenize()\n        self.split_camelcase()\n        self.normalize()\n        self.remove_stopwords()\n        self.remove_javakeywords()\n        self.stem()","metadata":{"id":"_22yeS4wcWpU","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:13.184689Z","iopub.execute_input":"2025-04-14T15:42:13.185047Z","iopub.status.idle":"2025-04-14T15:42:13.253126Z","shell.execute_reply.started":"2025-04-14T15:42:13.185026Z","shell.execute_reply":"2025-04-14T15:42:13.252216Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install inflection\nimport inflection\n","metadata":{"id":"ACZrz5Byh7Ur","outputId":"68b0fd14-1ac6-484a-cb84-2ab028bd5ed6","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:13.253984Z","iopub.execute_input":"2025-04-14T15:42:13.254286Z","iopub.status.idle":"2025-04-14T15:42:17.036734Z","shell.execute_reply.started":"2025-04-14T15:42:13.254249Z","shell.execute_reply":"2025-04-14T15:42:17.035600Z"}},"outputs":[{"name":"stdout","text":"Collecting inflection\n  Downloading inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\nDownloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\nInstalling collected packages: inflection\nSuccessfully installed inflection-0.5.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import nltk\nnltk.download('punkt_tab')\nimport pickle\nfrom google.colab import drive\nimport csv\nfrom collections import OrderedDict\nfrom datetime import datetime\nimport re\nimport string\nfrom nltk.stem.porter import PorterStemmer","metadata":{"id":"P9emxprnStnP","outputId":"51497efe-74ae-4abd-d5a0-485188dab6f7","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:17.038054Z","iopub.execute_input":"2025-04-14T15:42:17.038387Z","iopub.status.idle":"2025-04-14T15:42:17.109258Z","shell.execute_reply.started":"2025-04-14T15:42:17.038359Z","shell.execute_reply":"2025-04-14T15:42:17.108360Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Load d·ªØ li·ªáu","metadata":{"id":"SC6LbKkWy8kR"}},{"cell_type":"code","source":"glove_path = \"/kaggle/input/glove-embedding/glove.6B.100d.txt\"\n# Load GloVe 100d v√†o dictionary\nimport numpy as np\n\ndef load_glove_embeddings(filepath):\n    embeddings = {}\n    with open(filepath, 'r', encoding='utf-8') as f:\n        for line in f:\n            values = line.strip().split()\n            word = values[0]\n            vector = np.array(values[1:], dtype='float32')\n            embeddings[word] = vector\n    return embeddings\n    \nglove_embeddings = load_glove_embeddings(glove_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:17.110275Z","iopub.execute_input":"2025-04-14T15:42:17.110570Z","iopub.status.idle":"2025-04-14T15:42:28.471096Z","shell.execute_reply.started":"2025-04-14T15:42:17.110550Z","shell.execute_reply":"2025-04-14T15:42:28.470198Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import pickle\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c file pickle\nfile_paths = {\n    'aspectj': '/kaggle/input/bug-localization-data/aspectj_src_processed.pkl',\n    'eclipse': '/kaggle/input/bug-localization-data/eclipse_src_processed.pkl',\n    'swt': '/kaggle/input/bug-localization-data/swt_src_processed.pkl',\n    'tomcat': '/kaggle/input/bug-localization-data/tomcat_src_processed.pkl',\n    'birt': '/kaggle/input/bug-localization-data/birt_src_processed.pkl'\n}\n\n# Load t·ª´ng file v√† l∆∞u v√†o c√°c bi·∫øn t∆∞∆°ng ·ª©ng\ndatasets = {}\n\nfor name, path in file_paths.items():\n    with open(path, 'rb') as f:\n        datasets[name] = pickle.load(f)\n\n# Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c load v√†o c√°c bi·∫øn\nfor name, data in datasets.items():\n    print(f\"Data for {name}:\")\n","metadata":{"id":"O3TGVN1KzAXg","outputId":"63f347a7-1b8d-41fe-98e5-105ca43233e2","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:28.474037Z","iopub.execute_input":"2025-04-14T15:42:28.474329Z","iopub.status.idle":"2025-04-14T15:42:44.548548Z","shell.execute_reply.started":"2025-04-14T15:42:28.474306Z","shell.execute_reply":"2025-04-14T15:42:44.547661Z"}},"outputs":[{"name":"stdout","text":"Data for aspectj:\nData for eclipse:\nData for swt:\nData for tomcat:\nData for birt:\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"eclipse_src = datasets['eclipse']\nbirt_src = datasets['birt']\nswt_src = datasets['swt']\ntomcat_src = datasets['tomcat']\naspectj_src = datasets['aspectj']","metadata":{"id":"b91231aHzUu_","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:44.549324Z","iopub.execute_input":"2025-04-14T15:42:44.549571Z","iopub.status.idle":"2025-04-14T15:42:44.554749Z","shell.execute_reply.started":"2025-04-14T15:42:44.549545Z","shell.execute_reply":"2025-04-14T15:42:44.553780Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Load d·ªØ li·ªáu t·ª´ c√°c file pickle ƒë√£ l∆∞u\nfile_paths = {\n    'aspectj': '/kaggle/input/bug-localization-data/aspectj_reports_processed.pkl',\n    'eclipse': '/kaggle/input/bug-localization-data/eclipse_reports_processed.pkl',\n    'swt': '/kaggle/input/bug-localization-data/swt_reports_processed.pkl',\n    'tomcat': '/kaggle/input/bug-localization-data/tomcat_reports_processed.pkl',\n    'birt': '/kaggle/input/bug-localization-data/birt_reports_processed.pkl'\n}\n\n# Load t·ª´ng dataset v√† l∆∞u v√†o c√°c bi·∫øn\nall_processed_reports = {}\n\nfor name, path in file_paths.items():\n    with open(path, 'rb') as f:\n        all_processed_reports[name] = pickle.load(f)\n\n# Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ load v√†o\nfor dataset, reports in all_processed_reports.items():\n    print(f\"Processed reports for {dataset}:\")","metadata":{"id":"kXiYZuNgzv0M","outputId":"053bc2e9-ef09-4aea-9431-acfda03d3300","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:44.555681Z","iopub.execute_input":"2025-04-14T15:42:44.556002Z","iopub.status.idle":"2025-04-14T15:42:49.502063Z","shell.execute_reply.started":"2025-04-14T15:42:44.555976Z","shell.execute_reply":"2025-04-14T15:42:49.501247Z"}},"outputs":[{"name":"stdout","text":"Processed reports for aspectj:\nProcessed reports for eclipse:\nProcessed reports for swt:\nProcessed reports for tomcat:\nProcessed reports for birt:\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"eclipse_reports = all_processed_reports['eclipse']\nbirt_reports = all_processed_reports['birt']\nswt_reports = all_processed_reports['swt']\ntomcat_reports = all_processed_reports['tomcat']\naspectj_reports = all_processed_reports['aspectj']","metadata":{"id":"iAUv0Bnv0FcI","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.502973Z","iopub.execute_input":"2025-04-14T15:42:49.503309Z","iopub.status.idle":"2025-04-14T15:42:49.507824Z","shell.execute_reply.started":"2025-04-14T15:42:49.503289Z","shell.execute_reply":"2025-04-14T15:42:49.507188Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 2. X·ª≠ l√≠ data, g√°n nh√£n\n- S·∫Øp x·∫øp bug report theo th·ªùi gian (report_time)\n- Chia th√†nh 10 folds\n- T·∫°o training/test dataset theo ki·ªÉu fold i ‚Üí fold i+1\n- G√°n nh√£n cho t·ª´ng c·∫∑p (bug report, source file)","metadata":{"id":"-hwWTIRJ9PXd"}},{"cell_type":"code","source":"# B1: L·∫•y danh s√°ch (bug_id, bug_report), sau ƒë√≥ s·∫Øp x·∫øp theo report_time\nsorted_bug_reports = sorted(tomcat_reports.items(), key=lambda x: x[1].report_time)\ndata_src = tomcat_src","metadata":{"id":"HrKZiEgO9X16","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.508707Z","iopub.execute_input":"2025-04-14T15:42:49.508993Z","iopub.status.idle":"2025-04-14T15:42:49.539693Z","shell.execute_reply.started":"2025-04-14T15:42:49.508963Z","shell.execute_reply":"2025-04-14T15:42:49.538701Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def split_into_folds(sorted_reports, num_folds=10):\n    fold_size = len(sorted_reports) // num_folds\n    folds = [sorted_reports[i*fold_size:(i+1)*fold_size] for i in range(num_folds)]\n\n    # N·∫øu c√≤n d∆∞, r·∫£i ƒë·ªÅu v√†o c√°c fold ƒë·∫ßu\n    remainder = sorted_reports[num_folds*fold_size:]\n    for i, extra in enumerate(remainder):\n        folds[i].append(extra)\n    return folds\n\ndata_folds = split_into_folds(sorted_bug_reports, num_folds=10)\n","metadata":{"id":"fgRpuQKE9aA2","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.540814Z","iopub.execute_input":"2025-04-14T15:42:49.541089Z","iopub.status.idle":"2025-04-14T15:42:49.556615Z","shell.execute_reply.started":"2025-04-14T15:42:49.541069Z","shell.execute_reply":"2025-04-14T15:42:49.555496Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"i = 0 # th·ª≠ v·ªõi fold 0 ‚Üí 1\ntrain_fold = data_folds[i]\ntest_fold = data_folds[i+1]","metadata":{"id":"0itPPQ5O9cDT","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.557782Z","iopub.execute_input":"2025-04-14T15:42:49.558406Z","iopub.status.idle":"2025-04-14T15:42:49.573196Z","shell.execute_reply.started":"2025-04-14T15:42:49.558384Z","shell.execute_reply":"2025-04-14T15:42:49.572235Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import random\n\ndef generate_balanced_pairs(bug_fold, source_files, num_negatives_per_positive=50):\n    data = []\n    for bug_id, bug in bug_fold:\n        # Danh s√°ch file ch·ª©a bug (poszqitive)\n        positive_paths = set(bug.fixed_files)\n        positive = [\n            (bug_id, bug, src_path, source_files[src_path], 1)\n            for src_path in positive_paths if src_path in source_files\n        ]\n\n        # Danh s√°ch file c√≤n l·∫°i ƒë·ªÉ l·∫•y negative\n        all_paths = list(source_files.keys())\n        negative_paths = list(set(all_paths) - positive_paths)\n        sampled_negatives = random.sample(negative_paths, min(num_negatives_per_positive * len(positive), len(negative_paths)))\n\n        negative = [\n            (bug_id, bug, src_path, source_files[src_path], 0)\n            for src_path in sampled_negatives if src_path in source_files\n        ]\n\n        data.extend(positive + negative)\n    return data\ndef generate_all_negatives_pairs(bug_fold, source_files):\n    data = []\n    for bug_id, bug in bug_fold:\n        positive_paths = set(bug.fixed_files)\n        positive = [\n            (bug_id, bug, src_path, source_files[src_path], 1)\n            for src_path in positive_paths if src_path in source_files\n        ]\n\n        all_paths = list(source_files.keys())\n        negative_paths = list(set(all_paths) - positive_paths)\n\n        negative = [\n            (bug_id, bug, src_path, source_files[src_path], 0)\n            for src_path in negative_paths if src_path in source_files\n        ]\n\n        data.extend(positive + negative)\n    return data\n\n\ntrain_pairs = generate_balanced_pairs(train_fold, data_src, num_negatives_per_positive=50)\n#test_pairs = generate_balanced_pairs(test_fold, data_src, num_negatives_per_positive=50)\ntest_pairs = generate_all_negatives_pairs(test_fold, data_src)\n\n\n","metadata":{"id":"wjLEL9mR9fPv","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.574157Z","iopub.execute_input":"2025-04-14T15:42:49.574459Z","iopub.status.idle":"2025-04-14T15:42:49.720882Z","shell.execute_reply.started":"2025-04-14T15:42:49.574432Z","shell.execute_reply":"2025-04-14T15:42:49.720189Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"X·ª≠ l√≠ m·∫•t c√¢n b·∫±ng","metadata":{"id":"phVI5NPj-GMs"}},{"cell_type":"code","source":"def compute_stats(pairs):\n    total = len(pairs)\n    pos = sum(1 for _, _, _, _, label in pairs if label == 1)\n    neg = total - pos\n    ratio = pos / total if total > 0 else 0\n    return total, pos, neg, ratio\n\n  \ntotal, pos, neg, ratio = compute_stats(train_pairs)\nprint(\"üìä Train Set:\")\nprint(f\"  ‚û§ T·ªïng c·∫∑p: {total}\")\nprint(f\"  ‚úÖ Positive (label=1): {pos}\")\nprint(f\"  ‚ùå Negative (label=0): {neg}\")\nprint(f\"  ‚öñÔ∏è T·ª∑ l·ªá positive: {ratio:.4f}\")\n\ntotal, pos, neg, ratio = compute_stats(test_pairs)\nprint(\"\\nüß™ Test Set:\")\nprint(f\"  ‚û§ T·ªïng c·∫∑p: {total}\")\nprint(f\"  ‚úÖ Positive (label=1): {pos}\")\nprint(f\"  ‚ùå Negative (label=0): {neg}\")\nprint(f\"  ‚öñÔ∏è T·ª∑ l·ªá positive: {ratio:.4f}\")\n","metadata":{"id":"G-m4H5d79uzp","outputId":"1a4a413d-189b-4b5d-ca55-6552e56ce33f","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.722257Z","iopub.execute_input":"2025-04-14T15:42:49.722643Z","iopub.status.idle":"2025-04-14T15:42:49.737685Z","shell.execute_reply.started":"2025-04-14T15:42:49.722584Z","shell.execute_reply":"2025-04-14T15:42:49.736824Z"}},"outputs":[{"name":"stdout","text":"üìä Train Set:\n  ‚û§ T·ªïng c·∫∑p: 5355\n  ‚úÖ Positive (label=1): 105\n  ‚ùå Negative (label=0): 5250\n  ‚öñÔ∏è T·ª∑ l·ªá positive: 0.0196\n\nüß™ Test Set:\n  ‚û§ T·ªïng c·∫∑p: 190164\n  ‚úÖ Positive (label=1): 103\n  ‚ùå Negative (label=0): 190061\n  ‚öñÔ∏è T·ª∑ l·ªá positive: 0.0005\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### T·∫°o batches c√≥ bootstrapping (lu√¥n ch·ª©a √≠t nh·∫•t 1 positive sample)","metadata":{}},{"cell_type":"code","source":"def create_bootstrapped_batches(pairs, batch_size=128, pos_ratio=0.1):\n    positives = [p for p in pairs if p[-1] == 1]\n    negatives = [p for p in pairs if p[-1] == 0]\n\n    pos_per_batch = max(1, int(batch_size * pos_ratio))\n    neg_per_batch = batch_size - pos_per_batch\n\n    random.shuffle(positives)\n    random.shuffle(negatives)\n\n    batches = []\n    pos_idx, neg_idx = 0, 0\n\n    while neg_idx + neg_per_batch <= len(negatives):\n        pos_batch = []\n        for _ in range(pos_per_batch):\n            pos_batch.append(positives[pos_idx % len(positives)])\n            pos_idx += 1\n\n        neg_batch = negatives[neg_idx:neg_idx + neg_per_batch]\n        neg_idx += neg_per_batch\n\n        batch = pos_batch + neg_batch\n        random.shuffle(batch)\n        batches.append(batch)\n\n    return batches\n","metadata":{"id":"VVi_cbQD-a1b","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.738626Z","iopub.execute_input":"2025-04-14T15:42:49.739240Z","iopub.status.idle":"2025-04-14T15:42:49.758682Z","shell.execute_reply.started":"2025-04-14T15:42:49.739220Z","shell.execute_reply":"2025-04-14T15:42:49.757799Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"### Focal Loss Function","metadata":{}},{"cell_type":"code","source":"\ndef focal_loss(predictions, targets, alpha=0.999, gamma=2.0, eps=1e-6):\n    \"\"\"\n    predictions: tensor (batch_size,) - output sigmoid from model\n    targets: tensor (batch_size,) - true labels (0 or 1)\n    \"\"\"\n    # Avoid log(0)\n    predictions = predictions.clamp(min=eps, max=1.0 - eps)\n\n    # Compute focal loss\n    loss = -alpha * (1 - predictions)**gamma * targets * predictions.log() \\\n           - (1 - alpha) * predictions**gamma * (1 - targets) * (1 - predictions).log()\n    return loss.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.759684Z","iopub.execute_input":"2025-04-14T15:42:49.760039Z","iopub.status.idle":"2025-04-14T15:42:49.776183Z","shell.execute_reply.started":"2025-04-14T15:42:49.760012Z","shell.execute_reply":"2025-04-14T15:42:49.775085Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# 4. Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng","metadata":{}},{"cell_type":"markdown","source":"## 4.1. Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng tr·ª±c ti·∫øp t·ª´ token\n- L·∫•y token ƒë√£ x·ª≠ l√≠ t·ª´ ph·∫ßn Description + Summary (Concat) v√† Source code\n- Nh√∫ng Embedding b·∫±ng gLove dim = 100\n- Encoding th√¥ng qua 2 m√¥ h√¨nh CNN ri√™ng bi·ªát ƒë·ªÉ t·∫°o vector ƒë·∫∑c tr∆∞ng (128 chi·ªÅu)\n- Concatenate vector ƒë·∫∑c tr∆∞ng -> 256 chi·ªÅu\n- Chu·∫©n ho√° Min-Max","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\n# CNN encoder d√πng cho c·∫£ bug v√† source\nclass CNNEncoder(nn.Module):\n    def __init__(self, embed_dim=100, num_filters=64, kernel_sizes=(3, 5), dropout=0.5):\n        super(CNNEncoder, self).__init__()\n        self.convs = nn.ModuleList([\n            nn.Conv1d(in_channels=embed_dim, out_channels=num_filters, kernel_size=k)\n            for k in kernel_sizes\n        ])\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):  # x: (batch_size, seq_len, embed_dim)\n        x = x.permute(0, 2, 1)  # (batch, embed_dim, seq_len)\n        conv_outs = [F.relu(conv(x)) for conv in self.convs]\n        pooled = [F.max_pool1d(c, c.size(2)).squeeze(2) for c in conv_outs]\n        out = torch.cat(pooled, dim=1)\n        return self.dropout(out)  # shape: (batch_size, num_filters * len(kernel_sizes))\n\n# Token list ‚Üí batch embedding tensor\ndef batch_tokens_to_embeddings(batch_tokens, glove_dict, dim=100, max_len=100):\n    batch_embeddings = []\n    for tokens in batch_tokens:\n        emb = []\n        for token in tokens[:max_len]:\n            if token in glove_dict:\n                emb.append(glove_dict[token])\n            else:\n                emb.append(np.zeros(dim))\n        while len(emb) < max_len:\n            emb.append(np.zeros(dim))\n        batch_embeddings.append(emb)\n    return torch.tensor(np.array(batch_embeddings), dtype=torch.float32)\n\n# üÜï CNN feature extraction ‚Äì batch, nhanh, GPU, normalized\ndef extract_cnn_features_batch(pairs, glove_dict, bug_encoder, src_encoder, device=\"cuda\", dim=100, max_len=100):\n    bug_encoder = bug_encoder.to(device)\n    src_encoder = src_encoder.to(device)\n    bug_encoder.eval()\n    src_encoder.eval()\n\n    bug_token_list = []\n    src_token_list = []\n\n    for _, bug, _, src, _ in pairs:\n        bug_tokens = bug.summary['stemmed'] + bug.description['stemmed']\n        src_tokens = src.all_content['stemmed'] \n        bug_token_list.append(bug_tokens)\n        src_token_list.append(src_tokens)\n\n    # Embed ‚Üí tensor\n    bug_tensor = batch_tokens_to_embeddings(bug_token_list, glove_dict, dim, max_len).to(device)\n    src_tensor = batch_tokens_to_embeddings(src_token_list, glove_dict, dim, max_len).to(device)\n\n    # Forward CNN\n    with torch.no_grad():\n        bug_tensor = bug_tensor.to(device)\n        src_tensor = src_tensor.to(device)\n    \n        bug_vec = bug_encoder(bug_tensor)\n        src_vec = src_encoder(src_tensor)\n    \n        combined = torch.cat([bug_vec, src_vec], dim=1).cpu().numpy()  # chuy·ªÉn v·ªÅ CPU ƒë·ªÉ convert sang NumPy\n\n\n    # Normalize t·ª´ng chi·ªÅu v·ªÅ [0, 1]\n    min_vals = combined.min(axis=0)\n    max_vals = combined.max(axis=0)\n    denom = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n    normalized = (combined - min_vals) / denom\n\n    return normalized  # shape: (n_samples, 2*filters)\nimport torch\n\ndef extract_cnn_features_batch(pairs, glove_dict, bug_encoder, src_encoder, device=None, dim=100, max_len=100):\n    # T·ª± ƒë·ªông ch·ªçn thi·∫øt b·ªã: GPU n·∫øu c√≥, kh√¥ng th√¨ CPU\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    bug_encoder = bug_encoder.to(device)\n    src_encoder = src_encoder.to(device)\n    bug_encoder.eval()\n    src_encoder.eval()\n\n    bug_token_list = []\n    src_token_list = []\n\n    for _, bug, _, src, _ in pairs:\n        bug_tokens = bug.summary['stemmed'] + bug.description['stemmed']\n        src_tokens = src.all_content['stemmed'] \n        bug_token_list.append(bug_tokens)\n        src_token_list.append(src_tokens)\n\n    # Embed ‚Üí tensor\n    bug_tensor = batch_tokens_to_embeddings(bug_token_list, glove_dict, dim, max_len).to(device)\n    src_tensor = batch_tokens_to_embeddings(src_token_list, glove_dict, dim, max_len).to(device)\n\n    # Forward CNN\n    with torch.no_grad():\n        bug_vec = bug_encoder(bug_tensor)\n        src_vec = src_encoder(src_tensor)\n        combined = torch.cat([bug_vec, src_vec], dim=1).cpu().numpy()\n\n    # Normalize t·ª´ng chi·ªÅu v·ªÅ [0, 1]\n    min_vals = combined.min(axis=0)\n    max_vals = combined.max(axis=0)\n    denom = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n    normalized = (combined - min_vals) / denom\n\n    return normalized  # shape: (n_samples, 2 * filters)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:49.777346Z","iopub.execute_input":"2025-04-14T15:42:49.778177Z","iopub.status.idle":"2025-04-14T15:42:55.892885Z","shell.execute_reply.started":"2025-04-14T15:42:49.778151Z","shell.execute_reply":"2025-04-14T15:42:55.892109Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"bug_encoder = CNNEncoder()\nsrc_encoder = CNNEncoder()\nglove_dict=glove_embeddings\ncnn_combined_vector = extract_cnn_features_batch(train_pairs[:5000], glove_dict, bug_encoder, src_encoder)\nprint(\"‚úÖ CNN ƒë·∫∑c tr∆∞ng ƒë√£ chu·∫©n h√≥a:\", cnn_combined_vector.shape)\nprint(cnn_combined_vector[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:42:55.893718Z","iopub.execute_input":"2025-04-14T15:42:55.894116Z","iopub.status.idle":"2025-04-14T15:43:00.945809Z","shell.execute_reply.started":"2025-04-14T15:42:55.894096Z","shell.execute_reply":"2025-04-14T15:43:00.945138Z"}},"outputs":[{"name":"stdout","text":"‚úÖ CNN ƒë·∫∑c tr∆∞ng ƒë√£ chu·∫©n h√≥a: (5000, 256)\n[[0.8089047  0.2896923  0.41211054 ... 0.49028763 0.4774534  0.80815476]\n [0.8089047  0.2896923  0.41211054 ... 0.3551732  0.5252264  0.37926242]\n [0.8089047  0.2896923  0.41211054 ... 0.35755312 0.62323403 0.387725  ]\n ...\n [0.8089047  0.2896923  0.41211054 ... 0.3255381  0.52730614 0.36843655]\n [0.8089047  0.2896923  0.41211054 ... 0.41517264 0.5284032  0.6529414 ]\n [0.8089047  0.2896923  0.41211054 ... 0.54453754 0.3662719  0.3810035 ]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# H√†m x·ª≠ l√Ω text g·ªôp l·∫°i t·ª´ bug report\ndef bug_to_text(bug):\n    summary = bug.summary['unstemmed'] if isinstance(bug.summary, dict) else bug.summary\n    desc = bug.description['unstemmed'] if isinstance(bug.description, dict) else bug.description\n    return \" \".join(summary + desc)\n\n# H√†m x·ª≠ l√Ω text t·ª´ source file\ndef src_to_text(src):\n    content = src.all_content['unstemmed'] if isinstance(src.all_content, dict) else src.all_content\n    comments = src.comments['unstemmed'] if isinstance(src.comments, dict) else src.comments\n    return \" \".join(content + comments)\n","metadata":{"id":"4en89sb6-s54","outputId":"5c14ad2a-da00-495a-ec81-38687265bcfe","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:00.946748Z","iopub.execute_input":"2025-04-14T15:43:00.947053Z","iopub.status.idle":"2025-04-14T15:43:00.953726Z","shell.execute_reply.started":"2025-04-14T15:43:00.947023Z","shell.execute_reply":"2025-04-14T15:43:00.952910Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## 4.2. C√°c ƒë·∫∑c tr∆∞ng kh√°c\n### ƒê·∫∑c tr∆∞ng 1: T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng t·ª´ v·ª±ng (lexical similarity)\n- Ph∆∞∆°ng ph√°p: s·ª≠ d·ª•ng TF-IDF v√† cosine similarity.\n- Input: C·∫∑p d·ªØ li·ªáu (bug report, source file)\n- Output: m·∫£ng numpy ch·ª©a c√°c gi√° tr·ªã ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa bug report v√† source file cho m·ªói c·∫∑p.","metadata":{}},{"cell_type":"code","source":"def compute_lexical_similarity(pairs):\n    bug_texts = [bug_to_text(bug) for _, bug, _, _, _ in pairs]\n    src_texts = [src_to_text(src) for _, _, _, src, _ in pairs]\n\n    # G·ªôp c·∫£ bug + src l·∫°i ƒë·ªÉ fit chung vectorizer\n    combined = bug_texts + src_texts\n    tfidf = TfidfVectorizer()\n    tfidf_matrix = tfidf.fit_transform(combined)\n\n    # T√°ch ri√™ng l·∫°i t·ª´ng ph·∫ßn\n    bug_vecs = tfidf_matrix[:len(pairs)]\n    src_vecs = tfidf_matrix[len(pairs):]\n\n    # T√≠nh cosine cho t·ª´ng c·∫∑p (theo h√†ng t∆∞∆°ng ·ª©ng)\n    similarities = cosine_similarity(bug_vecs, src_vecs).diagonal()\n\n    return similarities\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:00.954803Z","iopub.execute_input":"2025-04-14T15:43:00.955140Z","iopub.status.idle":"2025-04-14T15:43:00.973738Z","shell.execute_reply.started":"2025-04-14T15:43:00.955119Z","shell.execute_reply":"2025-04-14T15:43:00.972813Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### ƒê·∫∑c tr∆∞ng 2: T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a (semantic similarity)\n- Ph∆∞∆°ng ph√°p: TF-IDF weighted average c·ªßa GloVe vectors v√† cosine similarity\n- Input:  (bug report, source file).\n- Output: M·ªôt m·∫£ng numpy ch·ª©a c√°c gi√° tr·ªã ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa bug report v√† source file cho m·ªói c·∫∑p, d·ª±a tr√™n GloVe vectors v√† tr·ªçng s·ªë TF-IDF.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ndef compute_semantic_similarity(pairs, glove_dict, dim=100):\n    bug_texts = [bug_to_text(bug) for _, bug, _, _, _ in pairs]\n    src_texts = [src_to_text(src) for _, _, _, src, _ in pairs]\n\n    # D√πng TF-IDF ƒë·ªÉ l·∫•y tr·ªçng s·ªë t·ª´\n    tfidf = TfidfVectorizer()\n    tfidf.fit(bug_texts + src_texts)\n    vocab = tfidf.vocabulary_\n    idf_weights = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n\n    def embed_text(text):\n        tokens = text.split()\n        vecs = []\n        weights = []\n        for token in tokens:\n            if token in glove_dict and token in vocab:\n                vecs.append(glove_dict[token])\n                weights.append(idf_weights[token])\n        if not vecs:\n            return np.zeros(dim)\n        vecs = np.array(vecs)\n        weights = np.array(weights).reshape(-1, 1)\n        weighted_vecs = vecs * weights\n        return weighted_vecs.sum(axis=0) / weights.sum()\n\n    # T√≠nh vector trung b√¨nh cho bug v√† src\n    bug_vecs = [embed_text(text) for text in bug_texts]\n    src_vecs = [embed_text(text) for text in src_texts]\n\n    # T√≠nh cosine similarity gi·ªØa t·ª´ng c·∫∑p\n    similarities = [cosine_similarity([b], [s])[0][0] for b, s in zip(bug_vecs, src_vecs)]\n\n    return np.array(similarities)\n","metadata":{"id":"BmKfMQ9oAFSQ","outputId":"e0bf60b5-8bc7-401f-c8ee-5e8ac04ebe01","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:00.978210Z","iopub.execute_input":"2025-04-14T15:43:00.978500Z","iopub.status.idle":"2025-04-14T15:43:00.991387Z","shell.execute_reply.started":"2025-04-14T15:43:00.978478Z","shell.execute_reply":"2025-04-14T15:43:00.990451Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"### ƒê·∫∑c tr∆∞ng 3: Similar Bug Report Score ","metadata":{}},{"cell_type":"markdown","source":"‚Üí Ki·ªÉm tra xem bug report n√†y c√≥ gi·ªëng¬†**nh·ªØng bug report c≈© t·ª´ng s·ª≠a c√πng file ƒë√≥**¬†kh√¥ng?\n\n- `build_bug_fix_history(pairs)` ‚Üí XD l·ªãch s·ª≠ ch·ªânh s·ª≠a theo t·ª´ng file\n- `compute_similar_bug_score(pairs, history)`\n    - Input: pairs, history\n    - So s√°nh bug hi·ªán t·∫°i v√† bug c≈©:\n    \n    cosine_similarity(TfidfVectorizer().fit_transform([bug_now, bug_old]))[0, 1]\n    \n    - L·∫•y gi√° tr·ªã t∆∞∆°ng ƒë·ªìng cao nh·∫•t v·ª´a t√¨m ƒë∆∞·ª£c","metadata":{}},{"cell_type":"code","source":"def build_bug_fix_history(pairs):\n    history = {}\n    for bug_id, bug, src_path, _, label in pairs:\n        if label == 1:  # ch·ªâ t√≠nh c√°c bug th·∫≠t s·ª± s·ª≠a file\n            if src_path not in history:\n                history[src_path] = []\n            history[src_path].append((bug_id, bug.report_time, bug_to_text(bug)))\n    return history\n\n# ƒê·∫∑c tr∆∞ng 3: Similar Bug Report Score\ndef compute_similar_bug_score(pairs, history):\n    scores = []\n    for bug_id, bug, src_path, _, _ in pairs:\n        current_time = bug.report_time\n        current_text = bug_to_text(bug)\n\n        sim_scores = []\n        if src_path in history:\n            for hist_bug_id, hist_time, hist_text in history[src_path]:\n                if hist_time < current_time:  # ch·ªâ t√≠nh bug trong qu√° kh·ª©\n                    sim = cosine_similarity(\n                        TfidfVectorizer().fit_transform([current_text, hist_text])\n                    )[0, 1]\n                    sim_scores.append(sim)\n        scores.append(max(sim_scores) if sim_scores else 0.0)\n    return np.array(scores)","metadata":{"id":"imb4_du_Bgjz","outputId":"8c08c8e9-7047-4e5d-de85-8b70e30cbe28","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:00.992416Z","iopub.execute_input":"2025-04-14T15:43:00.992663Z","iopub.status.idle":"2025-04-14T15:43:01.015089Z","shell.execute_reply.started":"2025-04-14T15:43:00.992644Z","shell.execute_reply":"2025-04-14T15:43:01.014153Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"### ƒê·∫∑c trung 4: Time Since Last Fix (ng√†y, normalize)\n- Ki·ªÉm tra v·ªõi m·ªói `(bug report, source file)` xem t·ª´ng ƒë∆∞·ª£c s·ª≠a tr∆∞·ªõc ƒë√≥ kh√¥ng v√† l·∫ßn cu·ªëi khi n√†o\n    - ƒê√£ l√¢u k s·ª≠a ‚Üí √çt l·ªói ‚Üí ƒêi·ªÉm th·∫•p\n    - M·ªõi s·ª≠a ‚Üí c√≥ th·ªÉ li√™n quan t·ªõi l·ªói ‚Üí ƒêi·ªÉm cao\n- C√°ch hƒë:\n    - T√¨m th·ªùi ƒëi·ªÉm bug current_time\n    - T√¨m history c√°c l·∫ßn s·ª≠a file trong qu√° kh·ª©\n    - T√≠nh kho·∫£ng c√°ch time gi·ªØa current v√† history g·∫ßn nh·∫•t\n    - Ch∆∞a s·ª≠a ‚Üí G√°n s·ªë delta_days=9999\n    - Chu·∫©n ho√°","metadata":{}},{"cell_type":"code","source":"# ƒê·∫∑c tr∆∞ng 4: Time Since Last Fix (ng√†y, normalize)\ndef compute_time_since_last_fix(pairs, history):\n    scores = []\n    for _, bug, src_path, _, _ in pairs:\n        current_time = bug.report_time\n        if src_path in history:\n            past_times = [hist_time for _, hist_time, _ in history[src_path] if hist_time < current_time]\n            if past_times:\n                delta_days = (current_time - max(past_times)).days\n            else:\n                delta_days = 9999  # C·ª±c l·ªõn n·∫øu ch∆∞a t·ª´ng s·ª≠a\n        else:\n            delta_days = 9999\n        scores.append(delta_days)\n\n    # Normalize v·ªÅ [0,1]\n    max_days = max(scores) if max(scores) != 0 else 1  # Tr√°nh chia cho 0\n\n    return np.array([1 - (s / max_days) for s in scores])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:01.016208Z","iopub.execute_input":"2025-04-14T15:43:01.016491Z","iopub.status.idle":"2025-04-14T15:43:01.034013Z","shell.execute_reply.started":"2025-04-14T15:43:01.016469Z","shell.execute_reply":"2025-04-14T15:43:01.033004Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"### ƒê·∫∑c tr∆∞ng 5: Fix Frequency (s·ªë l·∫ßn b·ªã s·ª≠a trong qu√° kh·ª©, normalize)\n\n\n- Ki·ªÉm tra xme m·ªói c·∫∑p ƒë∆∞·ª£c s·ª≠a bao nhi√™u l·∫ßn\n\n‚Üí S·ª≠a nhi·ªÅu ‚Üí File d·ªÖ d√≠nh l·ªói ‚Üí ƒêi·ªÉm cao","metadata":{}},{"cell_type":"code","source":"# ƒê·∫∑c tr∆∞ng 5: Fix Frequency (s·ªë l·∫ßn b·ªã s·ª≠a trong qu√° kh·ª©, normalize)\ndef compute_fix_frequency(pairs, history):\n    scores = []\n    for _, bug, src_path, _, _ in pairs:\n        current_time = bug.report_time\n        if src_path in history:\n            past_fixes = [1 for _, hist_time, _ in history[src_path] if hist_time < current_time]\n            freq = len(past_fixes)\n        else:\n            freq = 0\n        scores.append(freq)\n    # Normalize v·ªÅ [0,1] an to√†n\n    max_freq = max(scores)\n    max_freq = max(max_freq, 1)  # tr√°nh chia 0\n    return np.array([s / max_freq for s in scores])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:01.035192Z","iopub.execute_input":"2025-04-14T15:43:01.035469Z","iopub.status.idle":"2025-04-14T15:43:01.050944Z","shell.execute_reply.started":"2025-04-14T15:43:01.035434Z","shell.execute_reply":"2025-04-14T15:43:01.050125Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def min_max_normalize(values):\n    min_val = min(values)\n    max_val = max(values)\n    denom = max_val - min_val if max_val != min_val else 1\n    return [(v - min_val) / denom for v in values]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:01.052131Z","iopub.execute_input":"2025-04-14T15:43:01.052542Z","iopub.status.idle":"2025-04-14T15:43:01.072195Z","shell.execute_reply.started":"2025-04-14T15:43:01.052479Z","shell.execute_reply":"2025-04-14T15:43:01.071251Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"### ƒê·∫∑c tr∆∞ng 6: T√≠nh to√°n ƒë·ªãnh danh tr√πng l·∫∑p\n- T√≠nh to√°n s·ªë l∆∞·ª£ng c√°c ƒë·ªãnh danh (identifiers) tr√πng l·∫∑p gi·ªØa b√°o c√°o l·ªói v√† m√£ ngu·ªìn.\n- L·∫•y token bug.summary v√† bug.description gh√©p v√†o nhau; ƒë·ªìng th·ªùi l·∫•y t·∫•t c·∫£ t√™n class, method, bi·∫øn c·ªßa src_file\n- T√¨m t·∫≠p h·ª£p ph·∫ßn giao.\n- S·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ c·ªßa t·∫≠p giao ch√≠nh l√† s·ªë l∆∞·ª£ng ƒë·ªãnh danh tr√πng l·∫∑p\n- Chu·∫©n ho√° v·ªÅ [0,1]","metadata":{}},{"cell_type":"code","source":"def compute_identifier_overlap_count(pairs):\n    counts = []\n    for _, bug, _, src, _ in pairs:\n        bug_tokens = set(bug.summary['stemmed'] + bug.description['stemmed'])\n        identifiers = set(\n            src.class_names['stemmed'] + src.method_names['stemmed'] + src.variables['stemmed']\n        )\n        overlap = bug_tokens & identifiers\n        counts.append(len(overlap))\n    counts = np.array(counts)\n    # üîÑ Log normalization v·ªÅ [0,1]\n    return np.log1p(counts) / np.log1p(np.max(counts)) if counts.max() > 0 else np.zeros_like(counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:01.073182Z","iopub.execute_input":"2025-04-14T15:43:01.073481Z","iopub.status.idle":"2025-04-14T15:43:01.088116Z","shell.execute_reply.started":"2025-04-14T15:43:01.073448Z","shell.execute_reply":"2025-04-14T15:43:01.087175Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"### ƒê·∫∑c tr∆∞ng 7: T∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c\n- T√≠nh to√°n ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c gi·ªØa m·ªói c·∫∑p b√°o c√°o l·ªói (bug report) v√† t·ªáp m√£ ngu·ªìn (source file) trong danh s√°ch pairs\n- Chia src_file th√†nh 4 ph·∫ßn (Class_name, Methods_name, Comments, Variable), bug reports th√†nh 2 ph·∫ßn (description, summary)\n- V·ªõi m·ªói c·∫∑p (bug, source), n√≥ t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine d·ª±a tr√™n TF-IDF gi·ªØa t·ª´ng c·∫∑p ph·∫ßn nh·ªè c√≥ th·ªÉ c√≥ (v√≠ d·ª•: t√≥m t·∫Øt bug vs. t√™n l·ªõp source, t√≥m t·∫Øt bug vs. t√™n ph∆∞∆°ng th·ª©c source,... t·ªïng c·ªông 2*4=8 ph√©p so s√°nh).\n- C·ªông d·ªìn 8 ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng cosine n√†y l·∫°i ƒë·ªÉ ra m·ªôt ƒëi·ªÉm t·ªïng cho m·ªói c·∫∑p (bug, source).\n- Chu·∫©n ho√° [0,1]","metadata":{}},{"cell_type":"code","source":"def compute_structural_similarity(pairs):\n    \"\"\"\n    T√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c (structural similarity) gi·ªØa bug report v√† source file.\n    Bug report ƒë∆∞·ª£c chia th√†nh 2 ph·∫ßn: summary v√† description\n    Source file ƒë∆∞·ª£c chia th√†nh 4 ph·∫ßn: class, method, variable v√† comment\n    \n    Args:\n        pairs: Danh s√°ch c√°c c·∫∑p (bug_id, bug, src_path, src, label)\n        \n    Returns:\n        numpy array ch·ª©a ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c cho m·ªói c·∫∑p\n    \"\"\"\n    scores = []\n    for _, bug, _, src, _ in pairs:\n        # 1. Tr√≠ch xu·∫•t c√°c ph·∫ßn c·ªßa bug report\n        bug_segments = [\n            ' '.join(bug.summary['stemmed'] if isinstance(bug.summary, dict) else bug.summary),\n            ' '.join(bug.description['stemmed'] if isinstance(bug.description, dict) else bug.description)\n        ]\n        \n        # 2. Tr√≠ch xu·∫•t c√°c ph·∫ßn c·ªßa source file\n        # Class names segment\n        src_class = ' '.join(src.class_names['stemmed'] if isinstance(src.class_names, dict) else src.class_names)\n        \n        # Method names segment\n        src_method = ' '.join(src.method_names['stemmed'] if isinstance(src.method_names, dict) else src.method_names)\n        \n        # Variables segment (k·∫øt h·ª£p attributes v√† variables)\n        variables = src.variables['stemmed'] if isinstance(src.variables, dict) else src.variables\n        attributes = src.attributes['stemmed'] if isinstance(src.attributes, dict) else src.attributes\n        src_var = ' '.join(variables + attributes)\n        \n        # Comment segment\n        src_comment = ' '.join(src.comments['stemmed'] if isinstance(src.comments, dict) else src.comments)\n        \n        src_segments = [src_class, src_method, src_var, src_comment]\n        \n        # 3. T√≠nh t·ªïng ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng gi·ªØa m·ªói c·∫∑p ph·∫ßn \n        similarity_sum = 0\n        \n        for bug_segment in bug_segments:\n            for src_segment in src_segments:\n                if bug_segment and src_segment:  # B·ªè qua c√°c ph·∫ßn r·ªóng\n                    # T·∫°o TF-IDF vectors v√† t√≠nh cosine similarity\n                    tfidf = TfidfVectorizer()\n                    try:\n                        tfidf_matrix = tfidf.fit_transform([bug_segment, src_segment])\n                        if tfidf_matrix.shape[0] > 0 and tfidf_matrix.shape[1] > 0:\n                            sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n                            similarity_sum += sim\n                    except:\n                        pass  # B·ªè qua n·∫øu c√≥ l·ªói (v√≠ d·ª•: t√†i li·ªáu r·ªóng)\n        \n        scores.append(similarity_sum)\n    \n    # Chu·∫©n h√≥a scores v·ªÅ [0,1]\n    max_score = max(scores) if scores and max(scores) > 0 else 1\n    normalized_scores = np.array([score / max_score for score in scores])\n    \n    return normalized_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:01.089031Z","iopub.execute_input":"2025-04-14T15:43:01.089315Z","iopub.status.idle":"2025-04-14T15:43:01.101802Z","shell.execute_reply.started":"2025-04-14T15:43:01.089296Z","shell.execute_reply":"2025-04-14T15:43:01.101011Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# 4. Qu√° tr√¨nh hu·∫•n luy·ªán","metadata":{}},{"cell_type":"markdown","source":"## 4.1 T·∫°o ma tr·∫≠n train, test","metadata":{}},{"cell_type":"code","source":"def build_feature_matrix_batch(pairs_batch, glove_dict, bug_encoder, src_encoder, history, device=\"cuda\"):\n    # ƒê·∫∑c tr∆∞ng vector th∆∞·ªùng (1 chi·ªÅu)\n    lexical = compute_lexical_similarity(pairs_batch)                         # (N,)\n    semantic = compute_semantic_similarity(pairs_batch, glove_dict)          # (N,)\n    idf_overlap = compute_identifier_overlap_count(pairs_batch)              # (N,)               \n    structural= compute_structural_similarity(pairs_batch)                # (N,)\n    # ƒê·∫∑c tr∆∞ng d·ª±a v√†o l·ªãch s·ª≠ s·ª≠a l·ªói\n    similar_score = compute_similar_bug_score(pairs_batch, history)\n    recency = compute_time_since_last_fix(pairs_batch, history)\n    freq = compute_fix_frequency(pairs_batch, history)\n    # ƒê·∫∑c tr∆∞ng h·ªçc s√¢u (N, 256)\n    cnn_vec = extract_cnn_features_batch(pairs_batch, glove_dict, bug_encoder, src_encoder)\n\n    # Gh√©p to√†n b·ªô l·∫°i\n    X = np.hstack([\n        lexical.reshape(-1, 1),         \n        semantic.reshape(-1, 1),        \n        idf_overlap.reshape(-1, 1),     \n        structural.reshape(-1, 1),    \n        similar_score.reshape(-1, 1),\n        recency.reshape(-1, 1),\n        freq.reshape(-1, 1),\n        cnn_vec                         \n    ])  # ‚Üí T·ªïng c·ªông (N, 263)\n\n    return X\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:01.102873Z","iopub.execute_input":"2025-04-14T15:43:01.103358Z","iopub.status.idle":"2025-04-14T15:43:01.122248Z","shell.execute_reply.started":"2025-04-14T15:43:01.103329Z","shell.execute_reply":"2025-04-14T15:43:01.121300Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# T·∫°o nh√£n y\ndef get_labels(pairs):\n    return np.array([label for *_, label in pairs])\nglove_dict = glove_embeddings\nbug_history = build_bug_fix_history(train_pairs)\nX_train = build_feature_matrix_batch(train_pairs, glove_dict, bug_encoder, src_encoder,bug_history, device=device)\ny_train = get_labels(train_pairs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:23.092616Z","iopub.execute_input":"2025-04-14T15:43:23.092957Z","iopub.status.idle":"2025-04-14T15:44:42.666132Z","shell.execute_reply.started":"2025-04-14T15:43:23.092917Z","shell.execute_reply":"2025-04-14T15:44:42.665014Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def pair_generator(pairs, batch_size, glove_dict, history, bug_encoder, src_encoder, device=\"cuda\"):\n    for i in range(0, len(pairs), batch_size):\n        batch = pairs[i:i + batch_size]\n        X = build_feature_matrix_batch(batch, glove_dict, bug_encoder, src_encoder, history, device)\n        y = np.array([label for *_, label in batch])\n\n        yield torch.tensor(X, dtype=torch.float32).to(device), torch.tensor(y, dtype=torch.float32).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:45:00.701974Z","iopub.execute_input":"2025-04-14T15:45:00.702351Z","iopub.status.idle":"2025-04-14T15:45:00.708466Z","shell.execute_reply.started":"2025-04-14T15:45:00.702327Z","shell.execute_reply":"2025-04-14T15:45:00.707449Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"print(\"‚úÖ X_train shape:\", X_train.shape)  # \nprint(\"‚úÖ y_train shape:\", y_train.shape)  # ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:45:03.119733Z","iopub.execute_input":"2025-04-14T15:45:03.120108Z","iopub.status.idle":"2025-04-14T15:45:03.125609Z","shell.execute_reply.started":"2025-04-14T15:45:03.120084Z","shell.execute_reply":"2025-04-14T15:45:03.124538Z"}},"outputs":[{"name":"stdout","text":"‚úÖ X_train shape: (5355, 263)\n‚úÖ y_train shape: (5355,)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 4.2 X√¢y d·ª±ng m√¥ h√¨nh","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\n# ƒê·ªãnh nghƒ©a m√¥ h√¨nh DNN gi·ªëng b√†i b√°o\nimport torch\nimport torch.nn as nn\n\nclass BugLocalization(nn.Module):\n        def __init__(self, input_dim=5, hidden_dims=[128, 64], output_dim=1):\n            super(BugLocalization, self).__init__()\n\n            # Define a series of fully connected (Dense) layers\n            self.fc1 = nn.Linear(input_dim, hidden_dims[0])  # First hidden layer\n            self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])  # Second hidden layer\n            self.fc3 = nn.Linear(hidden_dims[1], output_dim)  # Output layer\n\n            # Define activation function (ReLU for hidden layers and Sigmoid for output)\n            self.relu = nn.ReLU()\n            self.sigmoid = nn.Sigmoid()\n\n        def forward(self, x):\n        # Forward pass through the DNN\n            x = self.relu(self.fc1(x))  # Pass through the first hidden layer with ReLU activation\n            x = self.relu(self.fc2(x))  # Pass through the second hidden layer with ReLU activation\n            x = self.sigmoid(self.fc3(x))  # Output layer with Sigmoid activation for binary classification\n            return x.squeeze()  # Remove extra dimension from the output (as it's a single value per input)\n\n\n\n        \n# ƒê·ªãnh nghƒ©a focal loss\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=0.999, gamma=2.0, eps=1e-6):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.eps = eps\n\n    def forward(self, preds, targets):\n        preds = preds.clamp(min=self.eps, max=1. - self.eps)\n        loss = -self.alpha * (1 - preds) ** self.gamma * targets * torch.log(preds) \\\n               - (1 - self.alpha) * preds ** self.gamma * (1 - targets) * torch.log(1 - preds)\n        return loss.mean()\n\n\n# Hu·∫•n luy·ªán m√¥ h√¨nh\ndef train_model_generator(model, train_gen, epochs=10, lr=1e-3):\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = FocalLoss()\n\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for batch_X, batch_y in train_gen:\n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n            # üßπ D·ªçn b·ªô nh·ªõ m·ªói batch\n            del batch_X, batch_y, outputs, loss\n            if device.type == \"cuda\":\n                torch.cuda.empty_cache()\n\n            import gc; gc.collect()\n\n        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f}\")\n\n","metadata":{"id":"LiD_wJxjDeQ8","outputId":"9821aee2-a66e-480b-9f69-6e4d207c7ba6","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:50:47.778338Z","iopub.execute_input":"2025-04-14T15:50:47.778643Z","iopub.status.idle":"2025-04-14T15:50:47.792722Z","shell.execute_reply.started":"2025-04-14T15:50:47.778623Z","shell.execute_reply":"2025-04-14T15:50:47.791455Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for X_batch, y_batch in pair_generator(\n    train_pairs, batch_size=128,\n    glove_dict=glove_embeddings,\n    history=bug_history,\n    bug_encoder=bug_encoder,\n    src_encoder=src_encoder, \n    device=device\n):\n    print(\"üëâ Feature shape:\", X_batch.shape)\n    print(\"üëâ Label shape:\", y_batch.shape)\n    print(\"üëâ Feature Sample [2]:\", X_batch[2].cpu().numpy())\n    print(\"üëâ Label Sample [2]:\", y_batch[2].item())\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:50:50.552630Z","iopub.execute_input":"2025-04-14T15:50:50.552976Z","iopub.status.idle":"2025-04-14T15:50:52.556653Z","shell.execute_reply.started":"2025-04-14T15:50:50.552950Z","shell.execute_reply":"2025-04-14T15:50:52.555747Z"}},"outputs":[{"name":"stdout","text":"üëâ Feature shape: torch.Size([128, 263])\nüëâ Label shape: torch.Size([128])\nüëâ Feature Sample [2]: [0.0214882  0.85669285 0.51191604 0.05740536 0.         0.\n 0.         1.         0.2981418  0.         0.         0.49893305\n 0.         1.         0.31768855 0.         0.4015461  0.12626755\n 0.         0.         1.         0.6665886  0.19880006 1.\n 1.         0.         0.19475457 0.         0.         0.89598125\n 0.         0.69855267 0.32368833 0.11286528 1.         0.\n 0.65008616 0.         1.         0.04610544 0.8906225  0.\n 0.         1.         1.         0.9777251  0.7598956  0.6824987\n 1.         0.         0.         0.15971081 0.63072574 0.\n 0.5738401  0.         0.39322913 0.43743396 0.44882277 1.\n 0.         0.         0.62319374 1.         0.         0.\n 0.46915498 0.         0.         0.69000065 0.94403845 1.\n 0.         0.         0.9115964  0.8460413  0.61618805 1.\n 0.         1.         0.75573486 1.         1.         0.81400055\n 1.         0.         0.7913204  1.         0.39025754 0.\n 0.         0.         0.8546332  1.         1.         0.66903555\n 0.97367346 0.         1.         0.         1.         0.7005896\n 0.05080169 0.32711798 0.         0.02676162 0.23907362 0.06448807\n 0.         0.47375032 0.77394927 0.67346746 0.3062917  0.\n 0.5739535  0.8360338  0.         1.         1.         0.\n 0.7451782  0.29476064 0.08901978 0.73522097 1.         0.\n 1.         0.         1.         1.         1.         0.\n 0.         1.         0.44297305 0.32041705 0.12234647 0.4871245\n 0.5173612  0.34305754 0.5246078  0.716608   0.21335892 0.31613594\n 0.44634405 0.22601439 0.1862901  0.3780124  0.3340391  0.50349396\n 0.62857586 0.47667235 0.32767382 0.4400996  0.55033827 0.45633066\n 0.13862967 0.25088704 0.46541783 0.32539672 0.5897411  0.47613427\n 0.60226095 0.65274984 0.44976586 0.76256907 0.5187119  0.4539592\n 0.38532463 0.16718848 0.57063097 0.33019426 0.19584258 0.34375384\n 0.37057158 0.43333343 0.55279416 0.5541607  0.42063957 0.4070192\n 0.5049039  0.54190093 0.5649716  0.5856532  0.36004528 0.7071822\n 0.4219659  0.37141836 0.8159413  0.6967476  0.22643225 0.45839489\n 0.5881432  0.21685411 0.8471951  0.5707684  0.6750797  0.20881431\n 0.6777968  0.38392484 0.56171644 0.23159084 0.16062619 0.34790078\n 0.5569599  0.36365056 0.41408673 0.54234123 0.49505168 0.21878923\n 0.52382386 0.18288983 0.30864614 0.6019138  0.6739586  0.54852694\n 0.44880435 0.641906   0.5913334  0.28642255 0.2878479  0.5369619\n 0.08854139 0.48774263 0.29253644 0.28459433 0.6407552  0.45669326\n 0.35202304 0.13159609 0.41979477 0.78166074 0.5783519  0.2879215\n 0.77677184 0.25048107 0.26437238 0.50033385 0.36605322 0.39676562\n 0.6648339  0.23166667 0.80497956 0.33228725 0.10818966 0.4255067\n 0.4463498  0.92340857 0.36719248 1.         0.35908818 0.6190779\n 0.608439   0.32563236 0.758      0.48267126 0.85233676 0.76649773\n 0.4890652  0.49191353 0.34140185 0.50810516 0.3592825 ]\nüëâ Label Sample [2]: 0.0\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def test_pair_generator(pairs, batch_size, glove_dict, history, bug_encoder, src_encoder, device=\"cuda\"):\n    for i in range(0, len(pairs), batch_size):\n        batch = pairs[i:i + batch_size]\n        X = build_feature_matrix_batch(batch, glove_dict, bug_encoder, src_encoder, history, device)\n\n        yield torch.tensor(X, dtype=torch.float32, device=device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:50:55.699637Z","iopub.execute_input":"2025-04-14T15:50:55.700002Z","iopub.status.idle":"2025-04-14T15:50:55.705857Z","shell.execute_reply.started":"2025-04-14T15:50:55.699978Z","shell.execute_reply":"2025-04-14T15:50:55.704802Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom sklearn.metrics import average_precision_score\nfrom collections import defaultdict\nimport numpy as np\n\n# ƒê√°nh gi√° c√°c ch·ªâ s·ªë (MAP, MRR, Top-k)\ndef compute_topk_accuracy(test_pairs, y_scores, k=10):\n    bug_to_scores = {}\n    for (bug_id, _, src_path, _, label), score in zip(test_pairs, y_scores):\n        if bug_id not in bug_to_scores:\n            bug_to_scores[bug_id] = []\n        bug_to_scores[bug_id].append((score, label))\n\n    correct_at_k = 0\n    total = 0\n\n    for entries in bug_to_scores.values():\n        sorted_entries = sorted(entries, key=lambda x: x[0], reverse=True)\n        top_k = sorted_entries[:k]\n        if any(label == 1 for _, label in top_k):\n            correct_at_k += 1\n        total += 1\n\n    return correct_at_k / total if total > 0 else 0\n\n\n\ndef compute_MAP_per_bug(test_pairs, y_pred_probs):\n    # Gom nh√£n v√† score theo bug_id\n    bug_to_ytrue = defaultdict(list)\n    bug_to_yscore = defaultdict(list)\n\n    for (bug_id, _, _, _, label), score in zip(test_pairs, y_pred_probs):\n        bug_to_ytrue[bug_id].append(label)\n        bug_to_yscore[bug_id].append(score)\n\n    # T√≠nh AP cho t·ª´ng bug, ch·ªâ gi·ªØ bug c√≥ √≠t nh·∫•t 1 label = 1\n    ap_list = []\n    for bug_id in bug_to_ytrue:\n        y_true = np.array(bug_to_ytrue[bug_id])\n        y_score = np.array(bug_to_yscore[bug_id])\n\n        if np.sum(y_true) == 0:\n            continue  # b·ªè qua bug kh√¥ng c√≥ file li√™n quan\n\n        ap = average_precision_score(y_true, y_score)\n        ap_list.append(ap)\n\n    # T√≠nh MAP\n    MAP = np.mean(ap_list) if ap_list else 0.0\n    return MAP\n\n# MRR (Mean Reciprocal Rank)\ndef mean_reciprocal_rank(pairs, scores):\n    bug_to_scores = {}\n    for (bug_id, _, _, _, label), score in zip(pairs, scores):\n        if bug_id not in bug_to_scores:\n            bug_to_scores[bug_id] = []\n        bug_to_scores[bug_id].append((score, label))\n\n    rr_sum = 0\n    count = 0\n    for bug_id, ranked in bug_to_scores.items():\n        ranked = sorted(ranked, key=lambda x: x[0], reverse=True)\n        for idx, (_, label) in enumerate(ranked):\n            if label == 1:\n                rr_sum += 1 / (idx + 1)\n                break\n        count += 1\n    return rr_sum / count if count > 0 else 0","metadata":{"id":"hvK-tE_MD4zq","outputId":"5444ce3e-4624-4f81-eb6b-b19a543b0d49","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:50:58.173499Z","iopub.execute_input":"2025-04-14T15:50:58.174445Z","iopub.status.idle":"2025-04-14T15:50:58.187266Z","shell.execute_reply.started":"2025-04-14T15:50:58.174405Z","shell.execute_reply":"2025-04-14T15:50:58.186209Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def build_feature_matrix_batch_large(\n    pairs, \n    glove_dict, \n    bug_encoder, \n    src_encoder, \n    history, \n    batch_size=20000, \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n):\n    all_features = []\n\n    for i in range(0, len(pairs), batch_size):\n        sub_batch = pairs[i:i+batch_size]\n        \n        # üî§ C√°c ƒë·∫∑c tr∆∞ng truy·ªÅn th·ªëng\n        lexical = compute_lexical_similarity(sub_batch)\n        semantic = compute_semantic_similarity(sub_batch, glove_dict)\n        idf_overlap = compute_identifier_overlap_count(sub_batch)\n        structural= compute_structural_similarity(sub_batch)     \n        # üß† C√°c ƒë·∫∑c tr∆∞ng t·ª´ l·ªãch s·ª≠ s·ª≠a l·ªói\n        similar_score = compute_similar_bug_score(sub_batch, history)\n        recency = compute_time_since_last_fix(sub_batch, history)\n        freq = compute_fix_frequency(sub_batch, history)\n\n        # üîç ƒê·∫∑c tr∆∞ng h·ªçc s√¢u\n        cnn = extract_cnn_features_batch(sub_batch, glove_dict, bug_encoder, src_encoder)\n\n        # üß© Gh√©p to√†n b·ªô ƒë·∫∑c tr∆∞ng\n        others = np.stack([\n            lexical, semantic, idf_overlap, structural, \n            similar_score, recency, freq\n        ], axis=1)\n\n        combined = np.concatenate([others, cnn], axis=1)\n        all_features.append(combined)\n\n        print(f\"‚úÖ Done {i+len(sub_batch)}/{len(pairs)} samples\")\n\n    return np.vstack(all_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:51:00.459230Z","iopub.execute_input":"2025-04-14T15:51:00.459560Z","iopub.status.idle":"2025-04-14T15:51:00.467700Z","shell.execute_reply.started":"2025-04-14T15:51:00.459538Z","shell.execute_reply":"2025-04-14T15:51:00.466369Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def run_kfold_training_and_eval(\n    folds,\n    source_files,\n    glove_dict,\n    bug_encoder,\n    src_encoder,\n    model_class,\n    k=10,\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    cache_dir=\"/kaggle/working\"\n):\n    results = {\n        \"fold\": [],\n        \"MAP\": [],\n        \"MRR\": [],\n        \"Top1\": [],\n        \"Top2\": [],\n        \"Top3\": [],\n        \"Top4\": [],\n        \"Top5\": [],\n        \"Top10\": [],\n        \"Top15\": []\n    }\n\n    for i in range(k - 1):\n        train_fold = [pair for j in range(i + 1) for pair in folds[j]]\n        test_fold = folds[i + 1]\n        \n\n        print(f\"\\nüì¶ Fold 0..{i} ‚û§ {i+1}\")\n\n        train_pairs = generate_balanced_pairs(train_fold, source_files, num_negatives_per_positive=50)\n        test_pairs = generate_all_negatives_pairs(test_fold, source_files)\n\n        if sum(1 for p in train_pairs if p[-1] == 1) < 1:\n            print(\"‚ö†Ô∏è B·ªè qua do qu√° √≠t positive samples\")\n            continue\n\n        train_X_path = os.path.join(cache_dir, f\"X_train_aspectj_fold{i}_263.npy\")\n        train_y_path = os.path.join(cache_dir, f\"y_train_aspectj_fold{i}_263.npy\")\n        test_X_path = os.path.join(cache_dir, f\"X_test_aspectj_fold{i+1}_263.npy\")\n        test_y_path = os.path.join(cache_dir, f\"y_test_aspectj_fold{i+1}_263.npy\")\n\n        if os.path.exists(train_X_path) and os.path.exists(train_y_path):\n            print(\"‚úÖ Load ƒë·∫∑c tr∆∞ng train t·ª´ cache\")\n            X_train = np.load(train_X_path)\n            y_train = np.load(train_y_path)\n        else:\n            print(\"üõ† Tr√≠ch ƒë·∫∑c tr∆∞ng train...\")\n            X_train = build_feature_matrix_batch_large(train_pairs, glove_dict, bug_encoder, src_encoder, bug_history,batch_size=20000, device=device)\n            y_train = get_labels(train_pairs)\n            np.save(train_X_path, X_train)\n            np.save(train_y_path, y_train)\n\n        if os.path.exists(test_X_path) and os.path.exists(test_y_path):\n            print(\"‚úÖ Load ƒë·∫∑c tr∆∞ng test t·ª´ cache\")\n            X_test = np.load(test_X_path)\n            y_test = np.load(test_y_path)\n        else:\n            print(\"üõ† Tr√≠ch ƒë·∫∑c tr∆∞ng test...\")\n            X_test = build_feature_matrix_batch_large(test_pairs, glove_dict, bug_encoder, src_encoder, bug_history,batch_size=20000, device=device)\n            y_test = get_labels(test_pairs)\n            np.save(test_X_path, X_test)\n            np.save(test_y_path, y_test)\n\n        print(\"‚úÖ Tr√≠ch xu·∫•t test done\")\n\n        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n                                      torch.tensor(y_train, dtype=torch.float32))\n        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n\n        model = model_class(input_dim=X_train.shape[1]).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = FocalLoss(alpha=0.99)\n\n        model.train()\n        print(\"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán\")\n        for epoch in range(10):\n            total_loss = 0\n            for batch_X, batch_y in train_loader:\n                batch_X = batch_X.to(device)\n                batch_y = batch_y.to(device)\n\n                optimizer.zero_grad()\n                outputs = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item()\n\n                del batch_X, batch_y, outputs, loss\n                torch.cuda.empty_cache()\n                import gc; gc.collect()\n\n            print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n\n        model.eval()\n        y_pred_probs = []\n        with torch.no_grad():\n            for i in range(0, len(X_test), 128):\n                batch_X = torch.tensor(X_test[i:i+128], dtype=torch.float32).to(device)\n                probs = model(batch_X).cpu().numpy()\n                y_pred_probs.extend(probs)\n\n        map_score = compute_MAP_per_bug(test_pairs, y_pred_probs)\n        mrr_score = mean_reciprocal_rank(test_pairs, y_pred_probs)\n        top1 = compute_topk_accuracy(test_pairs, y_pred_probs, k=1)\n        top2 = compute_topk_accuracy(test_pairs, y_pred_probs, k=2)\n        top3 = compute_topk_accuracy(test_pairs, y_pred_probs, k=3)\n        top4 = compute_topk_accuracy(test_pairs, y_pred_probs, k=4)\n        top5 = compute_topk_accuracy(test_pairs, y_pred_probs, k=5)\n        top10 = compute_topk_accuracy(test_pairs, y_pred_probs, k=10)\n        top15 = compute_topk_accuracy(test_pairs, y_pred_probs, k=15)\n\n        print(f\"‚úÖ Results:\")\n        print(f\"  ‚û§ MAP:   {map_score:.4f}\")\n        print(f\"  ‚û§ MRR:   {mrr_score:.4f}\")\n        print(f\"  ‚û§ Top@1: {top1:.4f} | Top@2: {top2:.4f} | Top@3: {top3:.4f}\")\n        print(f\"  ‚û§ Top@4: {top4:.4f} | Top@5: {top5:.4f} | Top@10: {top10:.4f} | Top@15: {top15:.4f}\")\n\n        results[\"fold\"].append(i)\n        results[\"MAP\"].append(map_score)\n        results[\"MRR\"].append(mrr_score)\n        results[\"Top1\"].append(top1)\n        results[\"Top2\"].append(top2)\n        results[\"Top3\"].append(top3)\n        results[\"Top4\"].append(top4)\n        results[\"Top5\"].append(top5)\n        results[\"Top10\"].append(top10)\n        results[\"Top15\"].append(top15)\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:51:02.891452Z","iopub.execute_input":"2025-04-14T15:51:02.891739Z","iopub.status.idle":"2025-04-14T15:51:02.911223Z","shell.execute_reply.started":"2025-04-14T15:51:02.891719Z","shell.execute_reply":"2025-04-14T15:51:02.910219Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cpu\")\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim  # ‚úÖ ph·∫ßn b·ªã thi·∫øu\nfrom sklearn.metrics import average_precision_score\nimport os\n\n\n\n\nresults = run_kfold_training_and_eval(\n    folds=data_folds,\n    source_files=data_src,\n    glove_dict=glove_dict,\n    bug_encoder=bug_encoder,\n    src_encoder=src_encoder,\n    model_class=BugLocalization,  # ho·∫∑c ImprovedBugLocalization\n    k=10,\n    device = torch.device(\"cpu\")\n)\n\n\n\n# Output full results\nprint(\"\\nFull Results:\")\nfor key, value in results.items():\n    print(f\"{key}: {value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:51:07.154843Z","iopub.execute_input":"2025-04-14T15:51:07.155200Z"}},"outputs":[{"name":"stdout","text":"\nüì¶ Fold 0..0 ‚û§ 1\n‚úÖ Load ƒë·∫∑c tr∆∞ng train t·ª´ cache\nüõ† Tr√≠ch ƒë·∫∑c tr∆∞ng test...\n‚úÖ Done 20000/190164 samples\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nfrom pathlib import Path\n\n# T·∫°o th∆∞ m·ª•c ƒë√≠ch n·∫øu ch∆∞a c√≥\noutput_dir = Path(\"/kaggle/working/input\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Duy·ªát qua t·∫•t c·∫£ file .npy trong /kaggle/input v√† c√°c th∆∞ m·ª•c con\nfor root, dirs, files in os.walk(\"/kaggle/input\"):\n    for file in files:\n        if file.endswith(\".npy\"):\n            src_path = os.path.join(root, file)\n            # T·∫°o ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ·ª©ng trong /kaggle/working/input\n            rel_path = os.path.relpath(src_path, \"/kaggle/input\")\n            dest_path = output_dir / rel_path\n            dest_path.parent.mkdir(parents=True, exist_ok=True)\n            shutil.copy2(src_path, dest_path)\n\n# N√©n th∆∞ m·ª•c ch·ª©a c√°c file .npy ƒë√£ copy th√†nh file zip\nshutil.make_archive(\"/kaggle/working/CNN_eclipse_263\", 'zip', \"/kaggle/working/input\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T15:43:01.172409Z","iopub.status.idle":"2025-04-14T15:43:01.172796Z","shell.execute_reply.started":"2025-04-14T15:43:01.172609Z","shell.execute_reply":"2025-04-14T15:43:01.172625Z"}},"outputs":[],"execution_count":null}]}